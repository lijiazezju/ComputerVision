# 摘要

* 主要有6000万个参数和65万个神经元组成的五个卷积层和三个全连接层组成。
* 为了解决较慢的算力的影响，首次在卷积神经网络使用了使用了RELU激活函数以及在GPU上实现了高效的2D卷积操作
* 首次在卷积神经网络中使用了“dropout”正则方法



# Introduction

* 当前的主流进行图像分类的方法主要采用机器学习方法，为了提高性能，需要更大的数据集，训练更厉害的模型，并且采用更多的方法来防止过拟合，但是之前只有数万级别的数据集，这样小的数据集进行简单的识别是很简单的，特别是如果保留标签进行数据增强的话，但真实的世界是更复杂，需要更大的数据集，现在已经有了1500万张，2200类的高分辨的数据集ImageNet。
* 任务复杂，即使Imagenet这样大的数据集也不行，模型需要先验知识，卷积神经网络正好满足这样的需求，下采用，卷积神经网络的感受野，局部连接和权值共享保留了相邻像素的相关性，符合真实的大千世界。比起相同大小的前馈神经网络，卷积神经网络更适合提取图像，有更小的参数可以更快的训练。
* 深度学习的关键：大规模的数据，硬件算力，模型算法。在网络中采用了不同寻常的操作和高效的基于GPU的卷积操作的实现在提高性能的同时缩短了训练的时间。就算有120万张图片，也会导致过拟合，采用了几种的防止过拟合的方法。
* 网络中每一个卷积层的都是必须的（<font color=red >现在看来这种观点不正确，可以采用更优的模型搭建方法让模型少一个卷积的情况下达到相同的性能</font>）
* 首先把图片裁减到256*256，然后进行预处理：计算出每张图片的均值，每个像素减去这个均值，减小对噪声的依赖性。



# 模型架构

![image-20220216133706712](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216133706712.png)

在第一层卷积和第二层卷积之后都是：Relu->LRN->最大池化。

* 第一层卷积：卷积核参数：kernel_size:11*11,padding:[1,2]即(左1，右2，上1，下2)，stride: 4,个数：96，输入[3,224,224]。(224-11+1+2)/4+1=55输出[96,55,55]
* 第一层最大池化层：kernel_size=3，padding=0,stride=2。输入[96,55,55]。（55-3)/2+1=27,输出：[96,27,27]。
* 第二层卷积：kernel_size:5*5,padding:[2,2],stride=1,个数256。输入[96,27,27]。(27-5+4)/1+1=27,输出[256,27,27]。
* 第二层最大池化层：kernel_size=3, padding=0,stride=2,输入[256,27,27],(27-3)/1+1=13，输出[256,13,13]。
* 第三层卷积：kernel_size=3,padding:[1,1],stride=1,个数：384，输入[256,13,13],(13-3+2)/1+1=13,输出[384,13,13].
* 第四层卷积：kernel_size=3,padding:[1,1],stride=1,个数：384，输入[384,13,13],(13-3+2)/1+1=13,输出[384,13,13].
* 第五层卷积：kenel_size=3,padding:[1,1],stride=1,个数：256，输入[384,13,13],(13-3+2)/1+1=13,输出[256,13,13].
* 第三层最大池化层：kernel_size=3,padding=0,stride=2,个数256，输入[256,13,13],(13-3)/2+1=6,输出[256,6,6].



# 结构创新点

1. 首次使用了不饱和的非线性的激活函数Relu，避免了梯度消失，收敛到25%的错误率时，比tanh快好几倍。

![image-20220216145202965](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216145202965.png)

2. 采用了多GPU并行训练。双GPU全参数的训练时间比单GPU半参数的训练时间更短，但是单GPU模型中最后一个卷积层和全连接层数量与双GPU全参数模型相同，因此半参数并不是真的只有一半的参数。
3. LRN局部对比度归一化，Relu不需要对输入的normalize来避免饱和。LRN即一个地方的神经元出现了高激活会对其他通道相同位置的神经元产生抑制作用，侧向抑制，与生物学的神经元类似，可以帮助泛化。N表示卷积核个数，即卷积之后的通道数，k是为了防止分母为0。<font color=red>但在VGG里面表示这个没有多大用，只会增加模型计算复杂度</font>

![image-20220216150744145](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216150744145.png)

4. 重叠的最大的池化，即池化步长小于池化窗口。可以防止过拟合，也可以提高正确率。<font color=red>现在也不使用重叠池化了</font>
5. 神经元的个数即**卷积的个数**，即卷积过后特征层的元素的个数，55 * 55 * 48 *2 -> 27 * 27 * 256 -> 13 * 13 * 384 -> 13 * 13 * 384 -> 13 * 13 * 256 ->4096 ->4096 ->1000

# 减少过拟合方法

模型有六千万个参数，但是还是容易过拟合，因此需要采取一定的方法去防止过拟合。

1. **数据增强**。<font color=red>减少图像过拟合最简单和最常见的方法是保留标签的认为放大数据集</font>

   * **平移和水平反转**，从256*256的图片中裁减224 * 224的图片，然后进行水平翻转，可以扩大2048的数据集，32 * 32 * 2=2048，如果不采用这样的方法会导致严重的过拟合，<font color=red>**会导致只能使用更小的网络。**</font><font color=blue>**提高准确率的技巧**：在测试阶段，对一张图片的中心，和四角分别获得一张图片，然后水平翻转，获得十张图片，将这十张图片分别放进网络中进行预测，然后融合（softmax）。</font>
   * **颜色变换**，对训练集的RGB三通道进行PCA降维，找到多个主成分，沿主成分的方法进行颜色变换能使图像更自然

   ​                                        $I_{xy}={[{I_{xy}}^R,{I_{xy}}^G,{I_{xy}}^B]}^T+[P_1,P_2,P_3]{[{\alpha}_1{\lambda}_1,{\alpha}_2{\lambda}_2,{\alpha}_3{\lambda}_3]}^T$
   
   ​                                             $\vec{p}_i$  ～ 指的是RGB协方差矩阵的特征向量
   
   ​                                            ${\lambda}_i$～RGB协方差矩阵的特征值
   
   ​											${\alpha}_i$～N（0，0.1）的随机数，每个只使用一次

2. Dropout随机失活 

   在训练阶段，每一个batch随机掐死一半的神经元（将神经元输出设为0）。阻断该神经元的前向传播和后向传播。预测阶段，保留所有神经元，预测结果乘以0.5。多个模型集成可以有效防止过拟合，但是对于大型神经网络而言资源消耗很大,dropout可以间接实现这个功能。每次随机失活一半的神经元，可以获得不同的残余网络，这些不同的网络共享权值。这样可以减少神经元的联合依赖适应性，强迫每个神经元都和随机不同的神经元相协作，让网络学习更有效的特征。会导致迭代伦数加倍。

## Dropout减少过拟合的原理

* 模型集成，共享$2^n$个共享权重的网络。
* 数据增强，总可以找到一张图片，使神经网络中间层结果与Dropout相同，相当于在数据集中多增加了这张图片。
* 模型记忆参数的随机性。
* 减少了神经元的的联合依赖性。

# 训练细节

* 使用随机梯度下降，batch_size=128。动量为0.9，权重衰减为0.0005,对应了损失函数的$L_2$正则化。权重衰减可以提高正确率同时起到了正确率的作用，pytorch里默认的Adam优化器的weight decay就是0.0005。

![image-20220216163326024](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216163326024.png)

* 用均值为0，标准差为0.01的高斯分布初始化权重，初始化第二个，第四个，第五个卷积层和全连接层的偏置为1，提高正输入来加速Relu学习的早期阶段。
* 学习率一开始初始化为0.01,当误差不再降低时学习率降低十倍。在120万张数据集上进行训练了六天。

# 实验结果

* 比起先提取特征的方法有更优秀的正确率。

​       ![image-20220216164205629](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216164205629.png)

* 在ILSVRC-2012上top-5错率率可以达到16.4%,如果在最后池化层后面加上一个卷积层，先在整个ImageNet Fall 2011数据集上预训练，再在ILSVRC-2012数据集上进行微调，top-5错误率可以达到16.6%,

![image-20220216164914404](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216164914404.png)

## 定性分析

* 第一个GPU训练的特征更倾向于提取边缘，频率，方向的特征，第二个GPU提取的特征偏向于颜色特征。

![image-20220216165308918](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216165308918.png)



* 网络可以提取到图片的语义特征。右边图像的第一列是测试集的五张图片，通过网络得到了4096向量，然后将测试集的图片都获得4096维的向量，找出每张图片欧式距离最小的六张图片，发现图像和相似。<font color=red>说明卷积网络可以提取语义信息</font>。

  ![image-20220216165839541](https://gitee.com/william-ljz/typora/raw/master/img/image-20220216165839541.png)

# 讨论

一个大而深的卷积神经网络可以在大数据集下产生很好的性能。每一个卷积层是必须的。为了简化训练，没有采用无监督预训练的方法。如果采用这个方法，正确率可能还会提高。

​    
